{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data : Forestfires\n",
    "Source : https://archive.ics.uci.edu/ml/datasets/Forest+Fires\n",
    "\n",
    "  P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data. \n",
    "  In J. Neves\n",
    "  Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence\n",
    "  Guimaraes\n",
    "  Available at: http://www.dsi.uminho.pt/~pcortez/fires.pdf\n",
    "\n",
    "1. Title: Forest Fires\n",
    "\n",
    "2. Sources\n",
    "   Created by: Paulo Cortez and An√≠bal Morais (Univ. Minho) @ 2007\n",
    "   \n",
    "3. Past Usage:\n",
    "\n",
    "   P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data.\n",
    "   In Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence\n",
    "   December\n",
    "   \n",
    "   In the above reference\n",
    "   Then\n",
    "   post-processed with the inverse of the ln(x+1) transform. Four different input setups were\n",
    "   used. The experiments were conducted using a 10-fold (cross-validation) x 30 runs. Two\n",
    "   regression metrics were measured: MAD and RMSE. A Gaussian support vector machine (SVM) fed\n",
    "   with only 4 direct weather conditions (temp\n",
    "   12.71 +- 0.01 (mean and confidence interval within 95% using a t-student distribution). The\n",
    "   best RMSE was attained by the naive mean predictor. An analysis to the regression error curve\n",
    "   (REC) shows that the SVM model predicts more examples within a lower admitted error. In effect\n",
    "   the SVM model predicts better small fires\n",
    " \n",
    "4. Relevant Information:\n",
    "\n",
    "   This is a very difficult regression task. It can be used to test regression methods. Also\n",
    "   it could be used to test outlier detection methods\n",
    "   are there. Yet\n",
    "\n",
    "5. Number of Instances: 517 \n",
    "\n",
    "6. Number of Attributes: 12 + output attribute\n",
    "  \n",
    "   Note: several of the attributes may be correlated\n",
    "   feature selection.\n",
    "\n",
    "7. Attribute information:\n",
    "\n",
    "   For more information\n",
    "\n",
    "   1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "   2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "   3. month - month of the year: \"jan\" to \"dec\" \n",
    "   4. day - day of the week: \"mon\" to \"sun\"\n",
    "   5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n",
    "   6. DMC - DMC index from the FWI system: 1.1 to 291.3 \n",
    "   7. DC - DC index from the FWI system: 7.9 to 860.6 \n",
    "   8. ISI - ISI index from the FWI system: 0.0 to 56.10\n",
    "   9. temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "   10. RH - relative humidity in %: 15.0 to 100\n",
    "   11. wind - wind speed in km/h: 0.40 to 9.40 \n",
    "   12. rain - outside rain in mm/m2 : 0.0 to 6.4 \n",
    "   13. area - the burned area of the forest (in ha): 0.00 to 1090.84 \n",
    "   (this output variable is very skewed towards 0.0\n",
    "    sense to model with the logarithm transform). \n",
    "\n",
    "8. Missing Attribute Values: None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, the dependent variable is area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('forestfires.csv')\n",
    "data = data.drop(['month','day', 'rain','area'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_module(data):\n",
    "    features = data.drop(['area'], axis=1)\n",
    "    y = data['area']\n",
    "    features= features.reset_index()\n",
    "    y = y.reset_index()\n",
    "    data_rearranged = pd.merge(y,features,on = 'index', how = 'left')\n",
    "    data_rearranged = data_rearranged.drop(['index'], axis=1)\n",
    "    n = data.shape[1]\n",
    "    significant_r = 1.96/(sqrt(n))\n",
    "    data_temp = data \n",
    "    \n",
    "    def covariance(X, Y,data):\n",
    "        mean_x = X.mean()\n",
    "        mean_y = Y.mean()\n",
    "        data_temp = data.copy(deep=True)\n",
    "        data_temp['(xi-xbar)'] = X - mean_x\n",
    "        data_temp['(yi-ybar)'] = Y - mean_y\n",
    "        data_temp['(xi-xbar)(yi-ybar)'] = data_temp['(xi-xbar)']*data_temp['(yi-ybar)']\n",
    "        covariance = (data_temp['(xi-xbar)(yi-ybar)'].sum())/(n-1)\n",
    "        return covariance\n",
    "    \n",
    "    def standard_deviation(X,data):\n",
    "        mean_x = X.mean()\n",
    "        data_temp = data.copy(deep=True)\n",
    "        data_temp['(xi-xbar)'] = X - mean_x\n",
    "        data_temp['(xi-xbar)**2'] = data_temp['(xi-xbar)']*data_temp['(xi-xbar)']\n",
    "        variance = (data_temp['(xi-xbar)**2'].sum())/(n-1)\n",
    "        standard_deviation = sqrt(variance)\n",
    "        return standard_deviation \n",
    "    \n",
    "    def correlation_coefficient(cov, std_dev1, std_dev2):\n",
    "        corr_coeff = cov/(std_dev1*std_dev2)\n",
    "        return corr_coeff\n",
    "\n",
    "    def partial_correlation_coefficient(Y, X1, X2):\n",
    "        cov_y_x1 = covariance(Y, X1)\n",
    "        cov_y_x2 = covariance(Y, X2)\n",
    "        s_y = standard_deviation(Y)\n",
    "        s_x1 = standard_deviation(X1)\n",
    "        s_x2 = standard_deviation(X2)\n",
    "        r_y_x1 = cov_y_x1/(s_y*s_x1)\n",
    "        r_y_x2 = cov_y_x2/(s_y*s_x2)\n",
    "        numerator = r_y_x1 - r_y_x2\n",
    "        denominator = sqrt((1-r_y_x1**2)*(1-r_y_x2**2))\n",
    "        partial_corr_coeff = numerator/denominator\n",
    "        return partial_corr_coeff\n",
    "    \n",
    "    corr_matrix = []\n",
    "    \n",
    "    def correlation_matrix(data):\n",
    "        for i in range(n):\n",
    "            corr_matrix.append([])\n",
    "            for j in range(n):\n",
    "                cov = covariance(data[data.columns[i]], data[data.columns[j]],data)\n",
    "                std_dev1 = standard_deviation(data[data.columns[i]],data)\n",
    "                std_dev2 = standard_deviation(data[data.columns[j]],data)\n",
    "                corr_matrix[i].append(correlation_coefficient(cov, std_dev1, std_dev2))\n",
    "        return corr_matrix\n",
    "    \n",
    "    def multi_collinearity_module(data, significant_r):\n",
    "        corr_matrix = correlation_matrix(data)\n",
    "        \n",
    "        insignificant_features_index_list = []\n",
    "        \n",
    "        ### Removing insignficant features (for which r of y and x(i) < r_significant)\n",
    "        corr_mat = np.asarray(corr_matrix)\n",
    "        \n",
    "        for i in range(corr_mat.shape[1]):\n",
    "            if abs(corr_mat[0][i]) < significant_r:\n",
    "                insignificant_features_index_list.append(i-1)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        ### Removing multi-collinearity\n",
    "        \n",
    "        p = 1\n",
    "        q = 1\n",
    "        \n",
    "        while (p < corr_mat.shape[0]):\n",
    "            q+=1\n",
    "            while (q < corr_mat.shape[1]):\n",
    "                if corr_matrix[p][q] > significant_r :\n",
    "                    partial_correlation_coefficient1 = partial_correlation_coefficient(data['area'],data[data.columns[p]],data[data.columns[q]])\n",
    "                    partial_correlation_coefficient2 = partial_correlation_coefficient(data['area'],data[data.columns[q]],data[data.columns[p]])\n",
    "                    if partial_correlation_coefficient1 > significant_r:\n",
    "                        if partial_correlation_coefficient2 > significant_r:\n",
    "                            if partial_correlation_coefficient1 > partial_correlation_coefficient2:\n",
    "                                insignificant_features_index_list.append(q)\n",
    "                            else :\n",
    "                                insignificant_features_index_list.append(p)\n",
    "                        else : \n",
    "                            insignificant_features_index_list.append(q)\n",
    "                    else :\n",
    "                        if partial_correlation_coefficient2 > significant_r:\n",
    "                            insignificant_features_index_list.append(p)\n",
    "                        else :\n",
    "                            insignificant_features_index_list.append(p)\n",
    "                            insignificant_features_index_list.append(q)\n",
    "        return(insignificant_features_index_list)\n",
    "    \n",
    "    features_list = []\n",
    "    for i in range(1, data_rearranged.shape[1]+1):\n",
    "        features_list.append(i)\n",
    "    \n",
    "    insignificant_features_index_list = multi_collinearity_module(data_rearranged, significant_r)\n",
    "    significant_features_index_list = features_list - insignificant_features_index_list\n",
    "    return significant_features_index_list\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
